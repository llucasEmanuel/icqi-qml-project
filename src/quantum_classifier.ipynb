{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Classificador Quântico Variacional de Imagens Reais e Imagens Geradas por IA**\n","\n","- Gabriel Alves Gadelha de Melo\n","- Lucas Emanuel Sabino de Souza Lima"],"metadata":{"id":"XLIxEMwDAdnc"}},{"cell_type":"markdown","source":["# **Introdução**\n","\n","Nos últimos anos, a evolução dos modelos generativos de inteligência artificial, como GANs e Diffusion Models, tornou cada vez mais difícil distinguir imagens artificiais de imagens reais. Essa crescente complexidade levanta preocupações em diversas áreas, como segurança digital, jornalismo, arte e verificação de autenticidade. Nesse contexto, o presente trabalho propõe e compara duas abordagens distintas para a detecção automática de imagens geradas por IA: uma abordagem clássica, baseada em descritores manuais e redes neurais profundas, e uma abordagem híbrida, que incorpora circuitos quânticos variacionais para a tarefa de classificação binária.\n","\n","A primeira abordagem utiliza algoritmos e tratamento de imagens para alimentar o circuito variacional. Já a segunda, utiliza a extração de características visuais como entropia, cor, textura e componentes de Fourier, combinadas com arquiteturas como CNNs e Transformers para realizar a distinção entre imagens reais e artificiais. O objetivo principal deste projeto é analisar a viabilidade e o desempenho desses dois paradigmas, explorando o potencial da computação quântica como alternativa ou complemento a técnicas clássicas de aprendizado de máquina."],"metadata":{"id":"l1xIfbgsCAnR"}},{"cell_type":"markdown","source":["# **Pré-Processamento**\n","\n","Dataset utilizado: [Link do Kaggle](https://www.kaggle.com/datasets/osmankagankurnaz/dataset-of-ai-generated-fruits-and-real-fruits)"],"metadata":{"id":"n8HHRzKM4tFK"}},{"cell_type":"markdown","source":["## Padronização das Imagens"],"metadata":{"id":"MvOxXRk09ToL"}},{"cell_type":"code","source":["import os\n","import cv2\n","\n","# Caminho das imagens de entrada e saída\n","input_folder = \"image_dataset\"\n","output_folder = \"apple_dataset\"\n","\n","# Tamanho novo\n","new_size = (256, 256)\n","\n","# Criar a pasta de saída, se não existir\n","os.makedirs(output_folder, exist_ok=True)\n","\n","def save_and_rename_imgs(prefix):\n","    # Iterar sobre as imagens\n","    folder = os.path.join(input_folder, prefix)\n","    for id, filename in enumerate(os.listdir(folder)):\n","        if filename.lower().endswith((\".jpg\")):\n","            img_path = os.path.join(folder, filename)\n","\n","            # Ler imagem\n","            img = cv2.imread(img_path)\n","\n","            if img is None:\n","                print(f\"Unable to open: {img_path}\")\n","                continue\n","\n","            # Redimensionar imagem\n","            resized_img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n","\n","            # Renomear a imagem\n","            new_name = f\"{prefix}_apple{id}.jpg\"\n","            output_path = os.path.join(output_folder, prefix, new_name)\n","\n","            # Salvar a imagem\n","            cv2.imwrite(output_path, resized_img)\n","\n","            print(f\"Saved to: {output_path}\")\n","\n","if __name__ == \"__main__\":\n","    save_and_rename_imgs(\"ai\")\n","    save_and_rename_imgs(\"real\")\n","    print(\"All images saved and renamed\")"],"metadata":{"id":"L9__TOys9KWd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cálculo de Parâmetros"],"metadata":{"id":"EeX_zbd--Ad-"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from scipy.stats import entropy, circstd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","def get_image_params(image_path):\n","    img = cv2.imread(image_path)\n","    if img is None:\n","        print(f\"Image not found: {image_path}\")\n","        return None\n","\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    f = np.fft.fft2(gray)\n","    fshift = np.fft.fftshift(f)\n","    magnitude = np.abs(fshift)\n","\n","    media_magnitude = np.mean(magnitude)\n","    energia_total = np.sum(magnitude**2)\n","    maximo = np.max(magnitude)\n","    desvio_padrao = np.std(magnitude)\n","\n","    mag_norm = magnitude.flatten()\n","    mag_norm = mag_norm / np.sum(mag_norm)\n","    entropia = entropy(mag_norm + 1e-8)\n","\n","    # Redimensiona para 64x64 para manter padrão\n","    new_img = cv2.resize(img, (64, 64))\n","\n","    # HLS para hue, lightness, saturation\n","    hls = cv2.cvtColor(new_img, cv2.COLOR_BGR2HLS)\n","    H = hls[..., 0].astype(np.float32).flatten() * 2  # Hue em 0-360\n","    L = hls[..., 1].astype(np.float32).flatten()\n","    S = hls[..., 2].astype(np.float32).flatten()\n","\n","    # Chroma a partir do RGB\n","    B, G, R = cv2.split(new_img)\n","    B = B.astype(np.float32).flatten()\n","    G = G.astype(np.float32).flatten()\n","    R = R.astype(np.float32).flatten()\n","\n","    max_rgb = np.maximum(np.maximum(R, G), B)\n","    min_rgb = np.minimum(np.minimum(R, G), B)\n","    C = max_rgb - min_rgb  # Chroma\n","\n","    std_H = circstd(H, high=360, low=0)\n","    std_L = np.std(L)\n","    std_C = np.std(C)\n","    std_S = np.std(S)\n","\n","    return {\n","        \"fft_mean\": media_magnitude,\n","        \"fft_total_energy\": energia_total,\n","        \"fft_max\": maximo,\n","        \"fft_std\": desvio_padrao,\n","        \"fft_entropy\": entropia,\n","        \"std_hue\": std_H,\n","        \"std_chroma\": std_C,\n","        \"std_lightness\": std_L,\n","        \"std_saturation\": std_S\n","    }\n","\n","# Salva os parâmetros no arquivo params-dataset.csv\n","if __name__ == \"__main__\":\n","    results = {\n","        \"fft_mean\": [],\n","        \"fft_total_energy\": [],\n","        \"fft_max\": [],\n","        \"fft_std\": [],\n","        \"fft_entropy\": [],\n","        \"std_hue\": [],\n","        \"std_chroma\": [],\n","        \"std_lightness\": [],\n","        \"std_saturation\": [],\n","        \"ai_gen\": []\n","    }\n","\n","    for i in range(150):\n","        img_path = os.path.join(\"apple_dataset\", \"ai\", f\"ai_apple{i}.jpg\")\n","        params = get_image_params(img_path)\n","        if params is not None:\n","            for key in params:\n","                results[key].append(params[key])\n","            results[\"ai_gen\"].append(1)\n","\n","    for i in range(156):\n","        img_path = os.path.join(\"apple_dataset\", \"real\", f\"real_apple{i}.jpg\")\n","        params = get_image_params(img_path)\n","        if params is not None:\n","            for key in params:\n","                results[key].append(params[key])\n","            results[\"ai_gen\"].append(0)\n","\n","    df = pd.DataFrame(results)\n","\n","    scaler = MinMaxScaler(feature_range=(0, 100))\n","    cols_to_normalize = [col for col in df.columns if col != \"ai_gen\"]\n","    df[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])\n","\n","    CSV_PATH = \"params-dataset.csv\"\n","    df.to_csv(CSV_PATH, index=False)\n","\n","    print(f\"Parameters saved to {CSV_PATH}\")"],"metadata":{"id":"nboKTiqi9_Z1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model V-1**\n","\n","\n"],"metadata":{"id":"5jjhGeGl4zQj"}},{"cell_type":"markdown","source":["## Download do Dataset Pré-Processado\n"],"metadata":{"id":"k-HLI9S_0ELI"}},{"cell_type":"markdown","source":["Antes de executar o modelo, é recomendado baixar o arquivo .zip do dataset já pré-processado usando o seguinte link: [apple-dataset](https://drive.google.com/drive/u/2/folders/1rX2wiOHdqUQEFnnoxN2qCeXnlNnTUViD)\n","\n","Após baixar o arquivo compactado, faça upload dele para a sua sessão do Colab e em seguida execute a célula abaixo."],"metadata":{"id":"BYaAynh-0S7E"}},{"cell_type":"code","source":["!unzip apple_dataset.zip"],"metadata":{"id":"SjCp9jE7zc3R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Se não ocorreu nenhum erro e foi criado o diretório apple_dataset na sua sessão do Colab, você está pronto para executar o modelo!"],"metadata":{"id":"okklL4udz14L"}},{"cell_type":"markdown","source":["## Carregamento e Decomposição das Imagens\n","\n","Antes de enviar as imagens para o circuito quântico, devemos reduzir as suas dimensões, já que seria computacionalmente inviável passá-las para ele como uma matriz de $256\\times256$, por exemplo. Por causa disso, usamos o Principal Component Analysis (PCA), uma técnica que, de forma geral, decompõe a imagem em apenas as suas componentes mais representativas. Com isso, podemos usar esse algoritmo para reduzir as imagens para vetores de 8 dimensões, sendo cada dimensão posteriormente correspondente a um qubit."],"metadata":{"id":"SeTCr4rGGRGZ"}},{"cell_type":"code","source":["import os\n","import cv2\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np"],"metadata":{"id":"--6dX_5R8szX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_images(dir):\n","  vectors = []\n","  for file in os.listdir(dir):\n","    img_path = os.path.join(dir, file)\n","    img = cv2.imread(img_path)\n","    if img is None:\n","      print(f\"Image '{img_path}' not found\")\n","      continue\n","    img = cv2.resize(img, (32, 32))\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    # Transformação das matrizes das imagens em um vetor\n","    img_vector = img_rgb.flatten()\n","    vectors.append(img_vector)\n","  return np.array(vectors)"],"metadata":{"id":"Dx7p0HyxGh_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Definição dos paths das imagens\n","AI_PATH = os.path.join(\"apple_dataset\", \"ai\")\n","REAL_PATH = os.path.join(\"apple_dataset\", \"real\")\n","\n","# Carreganento das imagens reais e geradas por IA\n","real_imgs = load_images(REAL_PATH)\n","ai_imgs = load_images(AI_PATH)\n","\n","# Junta os dados\n","X_total = np.vstack([real_imgs, ai_imgs])\n","\n","# Rotulação dos dados\n","y_real = np.zeros(len(real_imgs))\n","y_ai = np.ones(len(ai_imgs))\n","y_total = np.concatenate([y_real, y_ai])\n","\n","# PCA para decompor as imagens em 8 componentes\n","pca = PCA(n_components=8)\n","X_pca = pca.fit_transform(X_total)\n","\n","# Normalização [0, π] para condizer com as rotações do circuito\n","scaler = MinMaxScaler(feature_range=(0, np.pi))\n","X_norm = scaler.fit_transform(X_pca)\n","\n","print(\"Normalized Images Shape:\", X_norm.shape) # 306 imagens de 8 componentes"],"metadata":{"id":"KZ9I0SG5GeLP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748796244749,"user_tz":180,"elapsed":1256,"user":{"displayName":"Lucas Emanuel Sabino de Souza Lima","userId":"13220183834789933410"}},"outputId":"c52ae626-2cf5-4902-b277-94cec4089848"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Normalized Images Shape: (306, 8)\n"]}]},{"cell_type":"markdown","source":["## Circuito Quântico Variacional\n","\n"],"metadata":{"id":"wVUJ9FPrwrR4"}},{"cell_type":"markdown","source":["Agora que os dados estão prontos para serem inseridos no circuito, podemos definir o circuito variacional propriamente dito."],"metadata":{"id":"19DFoEc56iU4"}},{"cell_type":"markdown","source":["Caso o *PennyLane* não esteja instalado na sua sessão do Colab, execute a célula abaixo."],"metadata":{"id":"jR0FbuonnYZB"}},{"cell_type":"code","source":["!pip install pennylane"],"metadata":{"id":"HU3Po1uAwqYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pennylane as qml\n","from pennylane import numpy as np\n","from pennylane.templates import StronglyEntanglingLayers, BasicEntanglerLayers\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","import matplotlib.pyplot as plt"],"metadata":{"id":"dF16jKXrAx5h","executionInfo":{"status":"ok","timestamp":1748796272079,"user_tz":180,"elapsed":11120,"user":{"displayName":"Lucas Emanuel Sabino de Souza Lima","userId":"13220183834789933410"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff59fc4c-a0b3-4767-fef7-d11032f0e1b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["NUM_QUBITS = 8\n","dev = qml.device(\"default.qubit\", wires=NUM_QUBITS)\n","\n","NUM_LAYERS_BASIC = 1\n","NUM_LAYERS_STRONGLY = 1\n","\n","# Inicialização aleatório dos pesos\n","weights_basic = torch.nn.Parameter(torch.randn(NUM_LAYERS_BASIC, NUM_QUBITS) * np.pi)\n","weights_strongly = torch.nn.Parameter(torch.randn(NUM_LAYERS_STRONGLY, NUM_QUBITS, 3) * np.pi)\n","\n","optimizer = torch.optim.Adam([weights_basic, weights_strongly], lr=0.1)\n","\n","# Definição do CQV\n","@qml.qnode(dev, interface=\"torch\")\n","def circuit(X, weights_basic, weights_strong):\n","  qml.AngleEmbedding(X, wires=range(NUM_QUBITS), rotation=\"X\")\n","  BasicEntanglerLayers(weights_basic, wires=range(NUM_QUBITS))\n","  StronglyEntanglingLayers(weights_strongly, wires=range(NUM_QUBITS))\n","  return qml.expval(qml.PauliZ(0))\n","\n","# Função de custo a ser minimizada = Hinge Loss\n","def hinge_loss(y_pred, y_true):\n","  losses = torch.clamp(1 - y_true * y_pred, min=0)\n","  return torch.mean(losses)"],"metadata":{"id":"wi5DMhBXD0eq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Embedding\n","\n","Executando uma validação cruzada nos dois modelos (embedding na amplitude com 3 qubits e embedding no ângulo em RY com 8 qubits), foram obtidas as seguintes métricas:\n","\n","<table>\n","  <tr>\n","    <th>Embedding</th>\n","    <th>Acurácia Média</th>\n","    <th>Desvio Padrão Acurácia</th>\n","    <th>Precisão Média</th>\n","    <th>Recall Média</th>\n","    <th>F1-Score Média</th>\n","  </tr>\n","  <tr>\n","    <td>Amplitude</td>\n","    <td>0.928</td>\n","    <td>0.037</td>\n","    <td>0.945</td>\n","    <td>0.907</td>\n","    <td>0.925</td>\n","  </tr>\n","  <tr>\n","    <td>Ângulo</td>\n","    <td>0.971</td>\n","    <td>0.030</td>\n","    <td>1.000</td>\n","    <td>0.940</td>\n","    <td>0.968</td>\n","  </tr>\n","</table>\n","\n","Como é possível observar, o modelo com embedding no ângulo performa melhor em todas as métricas, apesar de possuir um tempo de treinamento maior devido ao seu número de qubits. Por causa disso, optamos pelo Embedding no ângulo para o circuito final. Entretanto, se estivessemos trabalhando com um conjunto de dados mais complexo e precisassemos de mais features das imagens, o embedding na amplitude poderia ser mais interessante por sua maior escalabilidade.\n","\n","Ainda sobre o embedding no ângulo, fizemos testes com rotações em todos os eixos, mas a RX foi a que melhor performou.\n","\n","<table>\n","  <tr>\n","    <th>Eixo de Rotação</th>\n","    <th>Acurácia Média</th>\n","    <th>Desvio Padrão Acurácia</th>\n","    <th>Precisão Média</th>\n","    <th>Recall Média</th>\n","    <th>F1-Score Média</th>\n","  </tr>\n","  <tr>\n","    <td>RX</td>\n","    <td>0.974</td>\n","    <td>0.022</td>\n","    <td>0.987</td>\n","    <td>0.960</td>\n","    <td>0.973</td>\n","  </tr>\n","  <tr>\n","    <td>RY</td>\n","    <td>0.971</td>\n","    <td>0.030</td>\n","    <td>1.000</td>\n","    <td>0.940</td>\n","    <td>0.968</td>\n","  </tr>\n","</table>\n","\n","Apesar da RY ter uma maior precisão, notamos um certo desbalanceamento nas suas previsões, já que sempre que o modelo parecia muito conservador, apenas prevendo que a imagem era gerada por IA se tivesse \"certeza absoluta\", tendendo sempre a prever que a imagem era real se tivesse \"um pouco de dúvida\". O RZ não se encontra na tabela, pois, com ele, o modelo nunca previa que a imagem era gerada por IA, portanto descartamos a possibilidade de usá-lo rapidamente.\n"],"metadata":{"id":"gXU_8Jo7qjjx"}},{"cell_type":"markdown","source":["### Layers\n","Após algumas pesquisas, encontramos que os templates de layers `BasicEntanglerLayers` e `StronglyEntanglingLayers` do *PennyLane* eram boas escolhas para classificação. Por causa disso, testamos várias combinações dos dois, e em um treinamento com tamanho de batch igual a 32 e 20 epochs conseguimos as seguintes acurácias:\n","\n","<table>\n","  <tr>\n","    <th></th>\n","    <th>BasicEntanglerLayers</th>\n","    <th>StronglyEntanglingLayers</th>\n","    <th>Acurácia</th>\n","  </tr>\n","  <tr>\n","    <td>Teste 1</td>\n","    <td>0</td>\n","    <td>1</td>\n","    <td>0.968</td>\n","  </tr>\n","  <tr>\n","    <td>Teste 2</td>\n","    <td>0</td>\n","    <td>2</td>\n","    <td>0.984</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 3</td>\n","    <td>0</td>\n","    <td>3</td>\n","    <td>1.000</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 4</td>\n","    <td>3</td>\n","    <td>0</td>\n","    <td>0.645</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 5</td>\n","    <td>1</td>\n","    <td>1</td>\n","    <td>1.000</td>\n","  </tr>\n","</table>\n","\n","Como o Teste 5 desempenhou tão bem quanto o Teste 3, optamos por usar as layers do Teste 5, já que o modelo ficava mais simples e o treinamento era mais rápido. Além disso, testamos também um `BasicEntanglerLayers` após o `StronglyEntanglingLayers`, mas não performou tão bem quanto a ordem que está na tabela, alcançando uma acurácia de $95.2\\%$.\n"],"metadata":{"id":"qvQbAeiVnqkE"}},{"cell_type":"markdown","source":["### Otimizador\n","\n","Foram testados os otimizadores Adam e Nesterov usando as suas respectivas implementações do *PyTorch*.\n","Foram realizados treinamentos sob as mesmas circunstânceas com ambos (tamanho de batch igual a 32 e 20 epochs) e usando o circuito com as layers escolhidas anteriormente, de modo que o Adam atingiu $100\\%$ e o Nesterov, $91.9\\%$. Por causa disso, optamos pelo otimizador Adam."],"metadata":{"id":"30jz5jlHqrv2"}},{"cell_type":"markdown","source":["### Loss\n","\n","Inicialmente usamos a função de MSE (Mean Squared Error) como função de loss e a acurácia final atingia cerca de $60\\%$ a $70\\%$. Entretanto, após algumas pesquisas, encontramos que essa não era uma boa função para classificadores, sendo mais adequada para modelos de regressão. Portanto, optamos por testar a Hinge Loss e a Binary Cross Entropy, que eram mais adequadas para o nosso propósito. Feitos os testes sob as mesmas circunstâncias, obtivemos acurácias idênticas para as duas funções ($98.4\\%$) e optamos por usar a Hinge Loss, já que o treinamento era mais rápido com ela."],"metadata":{"id":"0QR6I_2NqvvX"}},{"cell_type":"markdown","source":["## Treinamento e Avaliação do Modelo"],"metadata":{"id":"q-2g-xZtqZUy"}},{"cell_type":"markdown","source":["Para a avaliação final do modelo, optamos por realizá-la usando validação cruzada, já que, dessa forma, conseguimos treinar e validar o modelo com diversas combinações de imagens do dataset, e observar se existe, por exemplo, overfitting.\n","\n","Realizamos a validação cruzada com 5 folds e 10 epochs por fold. Além disso, foram usados batches de tamanho 32 para treinar o modelo.\n","\n","O tamanho do batch foi obtido quando ainda era usado o MSE como função de loss, o que explica a acurácia baixa. Foram realizados testes com tamanhos de batch iguais a 16, 32, 64 e 128, obtendo as seguintes acurácias:\n","\n","<table>\n","  <tr>\n","    <th>Tamanho do Batch</th>\n","    <th>Acurácia</th>\n","  </tr>\n","  <tr>\n","    <td>16</td>\n","    <td>0.629</td>\n","   \n","  </tr>\n","  <tr>\n","    <td>32</td>\n","    <td>0.710</td>\n","    \n","  </tr>\n","    <tr>\n","    <td>64</td>\n","    <td>0.613</td>\n","    \n","  </tr>\n","    <tr>\n","    <td>128</td>\n","    <td>0.661</td>\n","</table>\n","\n","Como o tamanho de batch igual a 32 foi o que teve a melhor acurácia, ele foi o escolhido."],"metadata":{"id":"lyA8X-zI161M"}},{"cell_type":"code","source":["epochs = 10\n","batch_size = 32\n","scale_logits = 10\n","\n","X_data = X_norm\n","y_data = y_total\n","y_hinge = 2 * y_data - 1\n","\n","NUM_FOLDS = 5\n","skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n","\n","# Armazena métricas de todos os folds\n","all_fold_accuracies = []\n","all_fold_precisions = []\n","all_fold_recalls = []\n","all_fold_f1s = []\n","\n","for fold, (train_ind, valid_ind) in enumerate(skf.split(X_data, y_data), 1):\n","    print(f\"\\nFold: {fold}/{NUM_FOLDS}\")\n","\n","    X_train, X_valid = X_data[train_ind], X_data[valid_ind]\n","    y_train, y_valid = y_hinge[train_ind], y_hinge[valid_ind]\n","\n","    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","    X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n","    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n","    y_valid_tensor = torch.tensor(y_valid, dtype=torch.float32).unsqueeze(1)\n","\n","    num_samples = X_train_tensor.shape[0]\n","    num_batches = int(np.ceil(num_samples / batch_size))\n","\n","    for epoch in range(epochs):\n","        permutation = torch.randperm(num_samples)\n","        X_train_shuffled = X_train_tensor[permutation]\n","        y_train_shuffled = y_train_tensor[permutation]\n","\n","        epoch_loss = 0\n","\n","        for batch_id in range(num_batches):\n","            # Seleciona os indices de incio e fim de cada barch\n","            start = batch_id * batch_size\n","            end = min(start + batch_size, num_samples)\n","\n","            # Filtra o conjunto de dados de cada batch\n","            X_batch = X_train_shuffled[start:end]\n","            y_batch = y_train_shuffled[start:end]\n","\n","            # Evita acumular gradientes de outros batches\n","            optimizer.zero_grad()\n","\n","            # Faz as previsões\n","            outputs = torch.stack([circuit(x, weights_basic, weights_strongly) for x in X_batch]).unsqueeze(1)\n","\n","            # Multiplicação do output por uma escala para ajudar a minimizar a perda\n","            logits = outputs * scale_logits\n","\n","            # Calcula o loss\n","            loss = hinge_loss(logits, y_batch)\n","\n","            # Calcula a direção que deve mudar para reduzir o erro\n","            loss.backward()\n","\n","            # Otimizador atualiza os pesos do modelo\n","            optimizer.step()\n","\n","            # Acumula o loss de cada batch\n","            epoch_loss += loss.item() * (end - start)\n","\n","        # Calcula a média de loss dos batches para calcular o loss da epoch\n","        epoch_loss /= num_samples\n","        print(f\"Epoch {epoch + 1}/{epochs}: loss = {epoch_loss:.4f}\")\n","\n","    # Avaliação no conjunto de validação\n","    with torch.no_grad():\n","        outputs_valid = torch.stack([circuit(x, weights_basic, weights_strongly) for x in X_valid_tensor]).unsqueeze(1)\n","        logits_valid = outputs_valid * scale_logits\n","        preds_valid_binary = (logits_valid.numpy() > 0).astype(int)\n","\n","    # Converte a previsão para 0 ou 1\n","    y_valid_binary = ((y_valid_tensor + 1) / 2).numpy().astype(int)\n","\n","    acc_valid = accuracy_score(y_valid_binary, preds_valid_binary)\n","    prec_valid = precision_score(y_valid_binary, preds_valid_binary)\n","    rec_valid = recall_score(y_valid_binary, preds_valid_binary)\n","    f1_valid = f1_score(y_valid_binary, preds_valid_binary)\n","\n","    all_fold_accuracies.append(acc_valid)\n","    all_fold_precisions.append(prec_valid)\n","    all_fold_recalls.append(rec_valid)\n","    all_fold_f1s.append(f1_valid)\n","\n","    print(f\"Acurácia no fold {fold}: {acc_valid:.3f}\")\n","    print(f\"Precisão no fold {fold}: {prec_valid:.3f}\")\n","    print(f\"Recall no fold {fold}: {rec_valid:.3f}\")\n","    print(f\"F1-score no fold {fold}: {f1_valid:.3f}\")\n","\n","    # Matriz de confusão\n","    cm = confusion_matrix(y_valid_binary, preds_valid_binary)\n","    print(f\"Matriz de confusão no fold {fold}:\\n{cm}\")\n","\n","# Resultados finais\n","mean_acc = np.mean(all_fold_accuracies)\n","std_acc = np.std(all_fold_accuracies)\n","\n","mean_prec = np.mean(all_fold_precisions)\n","mean_rec = np.mean(all_fold_recalls)\n","mean_f1 = np.mean(all_fold_f1s)\n","\n","print(\"\\n=== Resultados finais ===\")\n","print(f\"Acurácia média: {mean_acc:.3f} ± {std_acc:.3f}\")\n","print(f\"Precisão média: {mean_prec:.3f}\")\n","print(f\"Recall médio:   {mean_rec:.3f}\")\n","print(f\"F1-score médio: {mean_f1:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDfWdhtgtwVQ","executionInfo":{"status":"ok","timestamp":1748804130400,"user_tz":180,"elapsed":640247,"user":{"displayName":"Lucas Emanuel Sabino de Souza Lima","userId":"13220183834789933410"}},"outputId":"020cd044-5d21-4853-df64-8985f5e2cfdb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Fold: 1/5\n","Epoch 1/10: loss = 0.6483\n","Epoch 2/10: loss = 0.4260\n","Epoch 3/10: loss = 0.2262\n","Epoch 4/10: loss = 0.0946\n","Epoch 5/10: loss = 0.0684\n","Epoch 6/10: loss = 0.0570\n","Epoch 7/10: loss = 0.0432\n","Epoch 8/10: loss = 0.0529\n","Epoch 9/10: loss = 0.0417\n","Epoch 10/10: loss = 0.0348\n","Acurácia no fold 1: 0.935\n","Precisão no fold 1: 0.933\n","Recall no fold 1: 0.933\n","F1-score no fold 1: 0.933\n","Matriz de confusão no fold 1:\n","[[30  2]\n"," [ 2 28]]\n","\n","Fold: 2/5\n","Epoch 1/10: loss = 0.0658\n","Epoch 2/10: loss = 0.0592\n","Epoch 3/10: loss = 0.0593\n","Epoch 4/10: loss = 0.0542\n","Epoch 5/10: loss = 0.0699\n","Epoch 6/10: loss = 0.0570\n","Epoch 7/10: loss = 0.0551\n","Epoch 8/10: loss = 0.0623\n","Epoch 9/10: loss = 0.0472\n","Epoch 10/10: loss = 0.0421\n","Acurácia no fold 2: 0.984\n","Precisão no fold 2: 1.000\n","Recall no fold 2: 0.967\n","F1-score no fold 2: 0.983\n","Matriz de confusão no fold 2:\n","[[31  0]\n"," [ 1 29]]\n","\n","Fold: 3/5\n","Epoch 1/10: loss = 0.0536\n","Epoch 2/10: loss = 0.0472\n","Epoch 3/10: loss = 0.0525\n","Epoch 4/10: loss = 0.0414\n","Epoch 5/10: loss = 0.0441\n","Epoch 6/10: loss = 0.0397\n","Epoch 7/10: loss = 0.0705\n","Epoch 8/10: loss = 0.0450\n","Epoch 9/10: loss = 0.0460\n","Epoch 10/10: loss = 0.0573\n","Acurácia no fold 3: 0.984\n","Precisão no fold 3: 1.000\n","Recall no fold 3: 0.967\n","F1-score no fold 3: 0.983\n","Matriz de confusão no fold 3:\n","[[31  0]\n"," [ 1 29]]\n","\n","Fold: 4/5\n","Epoch 1/10: loss = 0.0520\n","Epoch 2/10: loss = 0.0458\n","Epoch 3/10: loss = 0.0380\n","Epoch 4/10: loss = 0.0308\n","Epoch 5/10: loss = 0.0471\n","Epoch 6/10: loss = 0.0344\n","Epoch 7/10: loss = 0.0350\n","Epoch 8/10: loss = 0.0366\n","Epoch 9/10: loss = 0.0293\n","Epoch 10/10: loss = 0.0308\n","Acurácia no fold 4: 0.984\n","Precisão no fold 4: 1.000\n","Recall no fold 4: 0.967\n","F1-score no fold 4: 0.983\n","Matriz de confusão no fold 4:\n","[[31  0]\n"," [ 1 29]]\n","\n","Fold: 5/5\n","Epoch 1/10: loss = 0.0394\n","Epoch 2/10: loss = 0.0393\n","Epoch 3/10: loss = 0.0393\n","Epoch 4/10: loss = 0.0468\n","Epoch 5/10: loss = 0.0347\n","Epoch 6/10: loss = 0.0321\n","Epoch 7/10: loss = 0.0278\n","Epoch 8/10: loss = 0.0299\n","Epoch 9/10: loss = 0.0278\n","Epoch 10/10: loss = 0.0375\n","Acurácia no fold 5: 0.951\n","Precisão no fold 5: 1.000\n","Recall no fold 5: 0.900\n","F1-score no fold 5: 0.947\n","Matriz de confusão no fold 5:\n","[[31  0]\n"," [ 3 27]]\n","\n","=== Resultados finais ===\n","Acurácia média: 0.967 ± 0.020\n","Precisão média: 0.987\n","Recall médio:   0.947\n","F1-score médio: 0.966\n"]}]},{"cell_type":"markdown","source":["# **Model V-2**"],"metadata":{"id":"IePlGbLD42UK"}},{"cell_type":"markdown","source":["## Download do Dataset Pré-Processado"],"metadata":{"id":"TKs21LmsGUNL"}},{"cell_type":"markdown","source":["\n","\n","Antes de executar o modelo, é recomendado baixar o arquivo .zip do dataset criado em Cálculo de Parâmetro na parte de Pré-Processamento, usando o seguinte link: [params-dataset](https://drive.google.com/drive/folders/1Fup_vWfSOut8yUA7amQqspfPILGhBX_u?usp=sharing)\n","\n","Após baixar o arquivo compactado, faça upload dele para a sua sessão do Colab e em seguida execute a célula abaixo."],"metadata":{"id":"LTpIVbX5H8cg"}},{"cell_type":"code","source":["!unzip params-dataset.zip"],"metadata":{"id":"-uph2wDC4yKP","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748871647948,"user_tz":180,"elapsed":123,"user":{"displayName":"Lucas Emanuel Sabino de Souza Lima","userId":"13220183834789933410"}},"outputId":"0109dc82-cd33-440e-a0b5-47a20731c401"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  params-dataset.zip\n","  inflating: dataset_params.csv      \n"]}]},{"cell_type":"markdown","source":["Se não ocorreu nenhum erro e foi criado o diretório params-dataset na sua sessão do Colab, você está pronto para executar o modelo!"],"metadata":{"id":"tcU5xc_a8SSN"}},{"cell_type":"markdown","source":["## Carregamento e Normalização dos Dados"],"metadata":{"id":"dirk_DMELH9_"}},{"cell_type":"markdown","source":["Antes de irmos ao Circuito Quântico Variacional, devemos pegar os dados brutos do arquivo, normalizá-los e prepará-los para serem carregados no circuito. Para isso, devemos realizar o seguinte trecho de código."],"metadata":{"id":"DY8r-fgeXQop"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"TEL8uw_0LU5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Carrega o dataset salvo em um arquivo CSV\n","data = pd.read_csv('dataset_params.csv')\n","\n","#\n","df_ai_gen_1 = data[data['ai_gen'] == 1]\n","df_ai_gen_0 = data[data['ai_gen'] == 0]\n","\n","# Concatena os dois subconjuntos de dados balanceados em um único DataFrame, reindexando as linhas sequencialmente\n","data = pd.concat([df_ai_gen_1, df_ai_gen_0], ignore_index=True)\n","\n","# Matriz de atributos (features) extraídos das imagens\n","X = data[['fft_mean',\n","          'fft_total_energy',\n","          'fft_max',\n","          'fft_std',\n","          'fft_entropy',\n","          'std_hue',\n","          'std_chroma',\n","          'std_lightness',\n","          'std_saturation']].values\n","\n","# Vetor de rótulos (0 ou 1)\n","y = data['ai_gen'].values\n","\n","# O 'AmplitudeEmbedding' da PennyLane exige que o vetor de entrada seja um vetor de amplitude normalizado e com norma 1. Dito isso, usamos\n","# [0, 1] para garantir que o vetor de entrada seja compatível com o espaço de estados físicos de um sistema quântico simulado (normalização)\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","X_scaled = scaler.fit_transform(X)"],"metadata":{"id":"njJf7tgAMhyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Circuito Quântico Variacional"],"metadata":{"id":"NANAD3jf40RP"}},{"cell_type":"markdown","source":["Agora que os dados estão prontos para serem inseridos no circuito, podemos definir o circuito variacional propriamente dito."],"metadata":{"id":"YPR0-HRybkSw"}},{"cell_type":"markdown","source":["Caso o *PennyLane* não esteja instalado na sua sessão do Colab, execute a célula abaixo."],"metadata":{"id":"GDslBC3BbqFC"}},{"cell_type":"code","source":["!pip install pennylane"],"metadata":{"id":"kSkII17NbxFq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import pennylane as qml\n","from pennylane import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"sH0EG7x5lsTZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748871737041,"user_tz":180,"elapsed":2713,"user":{"displayName":"Lucas Emanuel Sabino de Souza Lima","userId":"13220183834789933410"}},"outputId":"a2267199-9098-4986-b3b3-5fccb23293ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Definições iniciais\n","n_qubits = 4\n","dev = qml.device(\"default.qubit\", wires=NUM_QUBITS)\n","\n","n_layers_basic = 1\n","n_layers_strong = 1\n","\n","# Definição do circuito variacional\n","@qml.qnode(dev)\n","def circuit(params_basic, params_strong, x):\n","    # Aplicação do Embedding Amplitude preenchendo com 0 as amplitudes vagas\n","    qml.templates.AmplitudeEmbedding(x, wires=range(NUM_QUBITS), normalize=True, pad_with=0.0)\n","    # Aplica templates\n","    qml.templates.StronglyEntanglingLayers(params_strong, wires=range(NUM_QUBITS))\n","    qml.templates.BasicEntanglerLayers(params_basic, wires=range(NUM_QUBITS))\n","    # Retorna o valor esperado\n","    return qml.expval(qml.PauliZ(0))\n","\n","# Funções auxiliares\n","# Transforma os valores esperados retornados pelo circuito em 0 ou 1, facilitando a classificação binária\n","def predict(params_basic, params_strong, x):\n","    preds = [circuit(params_basic, params_strong, xi) for xi in x]\n","    preds = np.sign(np.array(preds))\n","    return (preds + 1) // 2\n","\n","# Mede quão boa é a previsão quântica comparada ao valor real\n","def BinaryCrossEntropy(params_basic, params_strong, x, y):\n","    preds = [circuit(params_basic, params_strong, xi) for xi in x]\n","    probs = (np.array(preds) + 1) / 2\n","    eps = 1e-10\n","    probs = np.clip(probs, eps, 1 - eps)\n","    # Se o rótulo for 1, o termo ativo é np.log(probs), penalizando as previsões próximas de 0. Por outro lado,\n","    # se o rótulo for 0, o termo ativo é np.log(1 - probs), penalizando as previsões próximas de 1\n","    loss = - (y * np.log(probs) + (1 - y) * np.log(1 - probs))\n","    return np.mean(loss)"],"metadata":{"id":"JC4fTN5m2QRc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Embedding"],"metadata":{"id":"Dy9NdpyJY3Ox"}},{"cell_type":"markdown","source":["Executando uma validação cruzada nos quatro modelos (embedding na amplitude com 4 qubits e embedding no ângulo em RX, RY e RZ com 9 qubits), foram obtidas as seguintes métricas:\n","\n","<table>\n","  <tr>\n","    <th>Embedding</th>\n","    <th>Acurácia Média</th>\n","    <th>Desvio Padrão Acurácia</th>\n","    <th>Precisão Média</th>\n","    <th>Recall Média</th>\n","    <th>F1-Score Média</th>\n","  </tr>\n","  <tr>\n","    <td>Amplitude</td>\n","    <td>0.954</td>\n","    <td>0.018</td>\n","    <td>0.994</td>\n","    <td>0.913</td>\n","    <td>0.951</td>\n","  </tr>\n","  <tr>\n","    <td>Ângulo RX</td>\n","    <td>0.630</td>\n","    <td>0.047</td>\n","    <td>0.651</td>\n","    <td>0.540</td>\n","    <td>0.589</td>\n","  </tr>\n","  <tr>\n","    <td>Ângulo RY</td>\n","    <td>0.934</td>\n","    <td>0.014</td>\n","    <td>1.000</td>\n","    <td>0.867</td>\n","    <td>0.928</td>\n","  </tr>\n","  <tr>\n","    <td>Ângulo RZ</td>\n","    <td>0.503</td>\n","    <td>0.013</td>\n","    <td>0.197</td>\n","    <td>0.400</td>\n","    <td>0.264</td>\n","  </tr>\n","</table>\n","\n","Como é possível observar, o modelo com Embedding na Amplitude performa melhor que as demais. Devido a isso, optamos pelo Embedding na Amplitude para o circuito final. Além disso, esse método se torna mais vantajoso, uma vez que temos um menor número de qubits (4) em comparação com o Embedding no ângulo (9), tornando o circuito mais simples e rápido de simular."],"metadata":{"id":"hauHGWWAZefG"}},{"cell_type":"markdown","source":["### Layers"],"metadata":{"id":"OBlBnLoaGXZE"}},{"cell_type":"markdown","source":["Após algumas pesquisas, encontramos que os templates de layers `BasicEntanglerLayers` e `StronglyEntanglingLayers` do *PennyLane* eram boas escolhas para classificação. Por causa disso, testamos várias combinações dos dois, e em um treinamento com tamanho de batch igual a 32 e 20 epochs conseguimos as seguintes acurácias:\n","\n","<table>\n","  <tr>\n","    <th></th>\n","    <th>BasicEntanglerLayers</th>\n","    <th>StronglyEntanglingLayers</th>\n","    <th>Acurácia</th>\n","  </tr>\n","  <tr>\n","    <td>Teste 1</td>\n","    <td>0</td>\n","    <td>2</td>\n","    <td>0.937</td>\n","  </tr>\n","  <tr>\n","    <td>Teste 2</td>\n","    <td>0</td>\n","    <td>3</td>\n","    <td>0.905</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 3</td>\n","    <td>2</td>\n","    <td>0</td>\n","    <td>0.827</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 4</td>\n","    <td>3</td>\n","    <td>0</td>\n","    <td>0.866</td>\n","  </tr>\n","    <tr>\n","    <td>Teste 5</td>\n","    <td>1 (primeiro)</td>\n","    <td>1 (segundo)</td>\n","    <td>0.951</td>\n","  </tr>\n","  </tr>\n","    <tr>\n","    <td>Teste 6</td>\n","    <td>1 (segundo)</td>\n","    <td>1 (primeiro)</td>\n","    <td>0.954</td>\n","  </tr>\n","</table>\n","\n","Apesar de não ter uma diferença significativa entre os dados, como o Teste 6 foi o com melhor performace, optamos por usar as layers testadas nele."],"metadata":{"id":"L7LzdlS7wy3q"}},{"cell_type":"markdown","source":["### Otimizador"],"metadata":{"id":"3Fl0ZYPfZgsr"}},{"cell_type":"markdown","source":["Foram testados os otimizadores Adam e Nesterov usando as suas respectivas implementações do *Pennylane*.\n","Foram realizados treinamentos sob as mesmas circunstânceas com ambos (tamanho de batch igual a 32 e 20 epochs) e usando o circuito com as layers escolhidas anteriormente, de modo que o Adam atingiu $94.7\\%$ de acurácia, já o Nesterov, $95.4\\%$. Apesar da pequena diferença, optamos pelo otimizador Nesterov neste modelo."],"metadata":{"id":"HRcS4ZUVz88z"}},{"cell_type":"markdown","source":["### Loss"],"metadata":{"id":"--kPLDkQZqk_"}},{"cell_type":"markdown","source":["Inicialmente usamos a função de MSE (Mean Squared Error) como função de loss e a acurácia final atingia cerca de $65\\%$ a $80\\%$. Entretanto, após algumas pesquisas, encontramos que essa não era uma boa função para classificadores, sendo mais adequada para modelos de regressão. Portanto, optamos por testar a Hinge Loss e a Binary Cross Entropy, que eram mais adequadas para o nosso propósito. Feitos os testes sob as mesmas circunstâncias, observamos que as acurácias utilizando a Binary Cross Entropy foram melhores, devido a isso, optamos por utilizá-la, apesar de deixar o treinamento mais demorado."],"metadata":{"id":"dWidU8ZX038Y"}},{"cell_type":"markdown","source":["## Treinamento e Avaliação do Modelo"],"metadata":{"id":"rbRrJUQXZzOI"}},{"cell_type":"markdown","source":["Para a avaliação final do modelo, optamos por realizá-la usando validação cruzada, já que, dessa forma, conseguimos treinar e validar o modelo com diversas combinações de imagens do dataset, e observar se existe, por exemplo, overfitting.\n","\n","Realizamos a validação cruzada com 5 folds e 20 epochs por fold. Além disso, foram usados batches de tamanho 32 para treinar o modelo.\n","\n","Foram realizados testes com tamanhos de batch iguais a 16, 32, 64 e 128, obtendo as seguintes acurácias:\n","\n","<table>\n","  <tr>\n","    <th>Tamanho do Batch</th>\n","    <th>Acurácia</th>\n","  </tr>\n","  <tr>\n","    <td>16</td>\n","    <td>0.958</td>\n","   \n","  </tr>\n","  <tr>\n","    <td>32</td>\n","    <td>0.954</td>\n","    \n","  </tr>\n","    <tr>\n","    <td>64</td>\n","    <td>0.905</td>\n","    \n","  </tr>\n","    <tr>\n","    <td>128</td>\n","    <td>0.735</td>\n","</table>\n","\n","Apesar do batch com tamanho 16 apresentar resultados ligeiramente melhores que o de 32, escolhemos seguir com o batch de 32 para \"padronizar\" o treinamento de ambos os medelos."],"metadata":{"id":"-iYi8SsE2L29"}},{"cell_type":"code","source":["# Inicialização de listas para armazenar métricas\n","all_fold_accuracies = []\n","all_fold_precisions = []\n","all_fold_recalls = []\n","all_fold_f1s = []\n","\n","# Cria o objeto Skf que divide o conjunto de dados em 5 folds preservando a proporção, evitando, assim, um viés\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","for fold, (train_idx, test_idx) in enumerate(skf.split(X_scaled, y), 1):\n","    print(f\"\\nFold {fold}\")\n","\n","    # Divisão treino/teste para o fold atual\n","    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # Inicializa parâmetros com valores próximos de 0, com requires_grad=True permitindo a diferenciação automática,\n","    # garantindo que o circuito começe próximo do estado identidade, facilitando o aprendizado nos primeiros passos\n","    params_basic = qml.numpy.array(0.01 * np.random.randn(n_layers_basic, n_qubits), requires_grad=True)\n","    params_strong = qml.numpy.array(0.01 * np.random.randn(n_layers_strong, n_qubits, 3), requires_grad=True)\n","\n","    # Inicializa otimizador\n","    opt = qml.NesterovMomentumOptimizer(stepsize=0.01, momentum=0.9)\n","\n","    # Parâmetros\n","    epochs = 20\n","    batch_size = 32\n","\n","    for epoch in range(epochs):\n","        indices = np.random.permutation(len(X_train))\n","        # Embaralha os dados antes de dividir em batches, garantindo que cada minibatch seja representativo e variado\n","        X_train_shuffled = X_train[indices]\n","        y_train_shuffled = y_train[indices]\n","\n","        # Divide os dados em minibatches de tamanho 32\n","        for i in range(0, len(X_train), batch_size):\n","            X_batch = X_train_shuffled[i:i+batch_size]\n","            y_batch = y_train_shuffled[i:i+batch_size]\n","\n","            # Atualiza os parâmetros usando a função BinaryCrossEntropy como função de custo\n","            params_basic, params_strong = opt.step(\n","                lambda pb, ps: BinaryCrossEntropy(pb, ps, X_batch, y_batch),\n","                params_basic, params_strong\n","            )\n","\n","        train_loss = BinaryCrossEntropy(params_basic, params_strong, X_train, y_train)\n","        print(f\"Epoch {epoch+1}: Loss = {train_loss:.4f}\")\n","\n","    # Avaliação no conjunto de teste\n","    y_pred = predict(params_basic, params_strong, X_test)\n","    acc = accuracy_score(y_test, y_pred)\n","    prec = precision_score(y_test, y_pred)\n","    rec = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n","\n","    all_fold_accuracies.append(acc)\n","    all_fold_precisions.append(prec)\n","    all_fold_recalls.append(rec)\n","    all_fold_f1s.append(f1)\n","\n","    # % de acertos totais\n","    print(f\"Acurácia no fold {fold}: {acc:.3f}\")\n","    # Entre os que o modelo previu como 1, quantos eram realmente 1\n","    print(f\"Precisão no fold {fold}: {prec:.3f}\")\n","    # Entre os que realmente eram 1, quantos foram detectados\n","    print(f\"Recall no fold {fold}: {rec:.3f}\")\n","    # Média harmônica entre precisão e recall\n","    print(f\"F1-score no fold {fold}: {f1:.3f}\")\n","    print(f\"Matriz de confusão no fold {fold}:\\n{cm}\")\n","\n","# Resultados finais\n","print(f\"\\nMédia da Acurácia: {np.mean(all_fold_accuracies) * 100:.3f}% ± {np.std(all_fold_accuracies) * 100:.3f}%\")\n","print(f\"Precisão média: {np.mean(all_fold_precisions):.3f}\")\n","print(f\"Recall médio:   {np.mean(all_fold_recalls):.3f}\")\n","print(f\"F1-score médio: {np.mean(all_fold_f1s):.3f}\")"],"metadata":{"id":"tdCxXzCi2NgY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f94915a1-d451-4cc4-a8d3-ec6152e0a2ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Fold 1\n","Epoch 1: Loss = 0.6511\n","Epoch 2: Loss = 0.5326\n","Epoch 3: Loss = 0.4597\n","Epoch 4: Loss = 0.3990\n","Epoch 5: Loss = 0.3740\n","Epoch 6: Loss = 0.3670\n"]}]},{"cell_type":"markdown","source":["# **Conclusão**\n","\n","Observa-se que os modelos avaliados alcançam acurácias elevadas, demonstrando consistência nos resultados. No entanto, à medida que aumentamos a complexidade das imagens, pode ser necessário realizar ajustes nos modelos. O primeiro modelo se destaca por trabalhar com imagens mais diversas, já que reduz suas dimensões para vetores de tamanho 8, o que contribui para uma boa performance em cenários mais simples. Por outro lado, o segundo modelo mostra-se mais escalável e, com a adição de alguns parâmetros, é capaz de realizar predições satisfatórias mesmo em contextos mais complexos."],"metadata":{"id":"-VVhjdC7Bw9e"}},{"cell_type":"markdown","source":["# **Referências**\n","- GeeksforGeeks. (n.d.). Principal Component Analysis (PCA). Disponível em: https://www.geeksforgeeks.org/principal-component-analysis-pca/\n","\n","- Medium – Data Science. (2019). Principal Component Analysis Made Easy: A Step-by-Step Tutorial. Disponível em: https://medium.com/data-science/principal-component-analysis-made-easy-a-step-by-step-tutorial-184f295e97fe\n","\n","- Huynh, N. (n.d.). Understanding Loss Functions for Classification. Medium. Disponível em: https://medium.com/@nghihuynh_37300/understanding-loss-functions-for-classification-81c19ee72c2a\n","\n","- Pedregosa, F. et al. (n.d.). 3.1. Cross-validation: Evaluating Estimator Performance. scikit-learn. Disponível em: https://scikit-learn.org/stable/modules/cross_validation.html\n","\n","- PennyLane Documentation. (n.d.). Introduction to Templates. Disponível em: https://docs.pennylane.ai/en/stable/introduction/templates.html\n","\n","- Wang, J., Webster, M., & Joyce, T. (2023). Colour Statistics of Images Created by Generative AI. ResearchGate. Disponível em: https://www.researchgate.net/publication/387287689_Colour_statistics_of_images_created_by_generative-AI\n","\n","- Alam, M., Muneer, A., & Woo, W. (2024). UGAD: Universal Generative AI Detector Utilizing Frequency Fingerprint. ACM Digital Library. Disponível em: https://dl.acm.org/doi/10.1145/3627673.3680085\n","\n","- Yuan, L., Li, X., Zhang, Y., Zhang, J., Li, H., & Gao, X. (2025). MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection. arXiv preprint arXiv:1911.06465. Disponível em: https://arxiv.org/abs/1911.06465\n"],"metadata":{"id":"lgH-H9oQ_vRh"}}]}